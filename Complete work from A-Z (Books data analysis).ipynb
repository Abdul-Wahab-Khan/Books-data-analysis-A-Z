{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4777ee5f",
   "metadata": {},
   "source": [
    "# Asalam Alaikum, Hello and welcome to this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e8701",
   "metadata": {},
   "source": [
    "### This is some practical work from A - Z (getting data to visualizing the useful insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed7ef8",
   "metadata": {},
   "source": [
    "### I will get you step by step through this project to get you a better understanding of how I have done it, if you found any mistake and fault in it, feel free to comment so we can learn something together.\n",
    "\n",
    "##### best regards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe781e1",
   "metadata": {},
   "source": [
    "#### This project is based on books information, which I have collected this information from wikipedia website from the link below.\n",
    "#### This process starts with scraping data from wikipedia (List_of_best-selling_books) page, which has some tables containing information about different type of books and other useful information about the books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38141ac",
   "metadata": {},
   "source": [
    "### So let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193d253",
   "metadata": {},
   "source": [
    "#### 1st: we will scrape the data from web source, so we have imported the neccessary libraries, urllib for requesting and getting the html data, and BeautifulSoup for processing the html content. Pandas for data cleaning, analyzing of the data, and numpy for some calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ceb36",
   "metadata": {},
   "source": [
    "#### we will request to the url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80951b2e",
   "metadata": {},
   "source": [
    "### 1: Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d033a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_best-selling_books'\n",
    "page = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_bytes = page.read()\n",
    "html = html_bytes.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = html.find(\"<title>\") + len(\"<title>\")\n",
    "end_index = html.find(\"</title>\")\n",
    "title = html[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc4ff1",
   "metadata": {},
   "source": [
    "#### We will create an object of BeautifulSoup, and parse the html content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d82b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b2f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.select('img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc85780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.select('tbody')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e4d81",
   "metadata": {},
   "source": [
    "#### As you may see we can use the BeautifulSoup object to navigate through html elements so easily, and get attributes and content of the element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c2c1c",
   "metadata": {},
   "source": [
    "#### Now that we have scraped and parsed the data, the problem is that the data is so dirty. So, we should clean it first. first of all we will start getting the data from html tables and combine them and then eliminatethe \\n from whole data. we will start with cleaning and chaging the data to pandas DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b429ae",
   "metadata": {},
   "source": [
    "### 2: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSlashN(i):\n",
    "    return i.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e20a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getTableHeader(table):\n",
    "    headings = []\n",
    "    for th in table.tr:\n",
    "        headings.append(th.text)\n",
    "\n",
    "    try:\n",
    "        while 1==1:\n",
    "            headings.remove('\\n')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    headings = list(map(splitSlashN, headings))\n",
    "    \n",
    "    return headings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a9ff1",
   "metadata": {},
   "source": [
    "#### In here we have the method to get table's data and combine the whole data because the data were fetched in many tables and we should combine all of them. columns 'No. of installments' and Genre were available in some tables, we have assigned None to records with no 'No. of installments' or Genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTableData(table):\n",
    "    table_data = []\n",
    "    table_header = getTableHeader(table)\n",
    "\n",
    "    for row in table.findAll('tr'):\n",
    "        row_data = []    \n",
    "\n",
    "        for cell in row.findAll('td'):\n",
    "            row_data.append(cell.text)  \n",
    "\n",
    "        if(len(row_data) > 0):\n",
    "            data_item = {\"Book\": row_data[0],\n",
    "                     \"Author(s)\": row_data[1],\n",
    "                     \"Original language\": row_data[2]\n",
    "            }\n",
    "            \n",
    "            i = 3;\n",
    "            \n",
    "            if (('No. of installments' in table_header or 'No. of instalments' in table_header) and row_data[i] != None):\n",
    "                data_item['No. of installments'] = row_data[i];\n",
    "                i = i + 1\n",
    "            else:\n",
    "                data_item['No. of installments'] = None\n",
    "                \n",
    "            data_item[\"First published\"] = row_data[i] if row_data[i] != None else None\n",
    "            i = i + 1\n",
    "            data_item[\"Approximate sales\"] = row_data[i] if row_data[i] != None else None\n",
    "            i = i + 1\n",
    "            \n",
    "            try:\n",
    "                if ('Genre' in table_header):\n",
    "                    if (row_data[i] != None):\n",
    "                        data_item[\"Genre\"] = row_data[i]\n",
    "                    else:\n",
    "                        data_item['Genre'] = None\n",
    "                else:\n",
    "                    data_item['Genre'] = None\n",
    "            except:\n",
    "                data_item['Genre'] = None\n",
    "            \n",
    "            \n",
    "            table_data.append(data_item)\n",
    "                \n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_tables = soup.findAll('tbody')\n",
    "book_tables.pop()\n",
    "len(book_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f483dcc",
   "metadata": {},
   "source": [
    "#### we will call the getTableData method to get every html table's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8483dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_books = []\n",
    "\n",
    "for table in book_tables:\n",
    "    all_books.append(getTableData(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76bac7",
   "metadata": {},
   "source": [
    "#### We will convert the python list (which is populated with all of the data from html table's) into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d58ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df = pd.DataFrame()\n",
    "\n",
    "for table in all_books:\n",
    "    table = pd.DataFrame(table)\n",
    "    books_df = pd.concat([books_df, table]).reset_index(drop=True)\n",
    "    \n",
    "books_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fcc38e",
   "metadata": {},
   "source": [
    "#### First we will try to eliminate null rows and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ee84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f266e",
   "metadata": {},
   "source": [
    "#### We will eliminate the \\n, as its visible all over the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60eb68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cleanColumnsSlashN(value):\n",
    "    if (value is not None):\n",
    "        return value.split('\\n')[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "books_df['Book'] = books_df['Book'].apply(lambda x: cleanColumnsSlashN(x))\n",
    "books_df['Author(s)'] = books_df['Author(s)'].apply(lambda x: cleanColumnsSlashN(x))\n",
    "books_df['Original language'] = books_df['Original language'].apply(lambda x: cleanColumnsSlashN(x))\n",
    "books_df['No. of installments'] = books_df['No. of installments'].apply(lambda x: cleanColumnsSlashN(x))\n",
    "books_df['First published'] = books_df['First published'].apply(lambda x: cleanColumnsSlashN(x))\n",
    "books_df['Approximate sales'] = books_df['Approximate sales'].apply(lambda x: cleanColumnsSlashN(x))\n",
    "books_df['Genre'] = books_df['Genre'].apply(lambda x:cleanColumnsSlashN(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89275d71",
   "metadata": {},
   "source": [
    "#### We will now create some useful functions to elimiate extra characters and to remain only the number in Approximate sales column so that we can work with numbers easily in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSaleAmount(sale):\n",
    "    if (sale is not None):\n",
    "        s = sale.split(' ')\n",
    "        if (s[0][0].isdigit() or s[0][0] == '>'):\n",
    "            return s[0]\n",
    "        elif (s[1][0].isdigit()):\n",
    "            return s[1]\n",
    "        elif (s[2][0].isdigit()):\n",
    "            return s[2]\n",
    "        \n",
    "    return None\n",
    "\n",
    "def removeExtraCharacters(sale):\n",
    "    if (sale is not None):\n",
    "        s = sale.split('>')\n",
    "        if (len(s) > 1):\n",
    "            return s[1]\n",
    "        return sale\n",
    "    return None\n",
    "\n",
    "def removeExtraBrackets(sale):\n",
    "    if (sale is not None):\n",
    "        s = sale.split('[')\n",
    "        return s[0]\n",
    "    return None\n",
    "\n",
    "def removeDashFromSale(sale):\n",
    "    if (sale is not None):\n",
    "        s = sale.split('–')\n",
    "        if(len(s) > 1):\n",
    "            s = list([pd.to_numeric(s[0]), pd.to_numeric(s[1])])\n",
    "            sales = (s[1] + s[0])/2;\n",
    "            return sales\n",
    "        else:\n",
    "            return sale \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88755c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Approximate sales'] = books_df['Approximate sales'].apply(lambda x: getSaleAmount(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37132c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df['Approximate sales'] = books_df['Approximate sales'].apply(lambda x: removeExtraCharacters(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Approximate sales'] = books_df['Approximate sales'].apply(lambda x: removeExtraBrackets(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c596f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df['Approximate sales'] = books_df['Approximate sales'].apply(lambda x: removeDashFromSale(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d7194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df['Approximate sales'] = pd.to_numeric(books_df['Approximate sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6edac5",
   "metadata": {},
   "source": [
    "#### Now we have eliminated the extra charaters from Approximate sales column and coverted it to numeric, but first there are some values which were in range format, so we considered to take the average value of in the range and store that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5721ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df.loc[296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ebb10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df.loc[300:340]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7bb6c0",
   "metadata": {},
   "source": [
    "#### We will create a new column as for every book it has a specific type, as you can see it in the website it self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Book type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Book type'].loc[0:172] = 'Individual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Book type'].loc[173:294] = 'Series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10059e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Book type'].loc[295:] = 'Regularly Updated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ada964",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175435a6",
   "metadata": {},
   "source": [
    "#### Its time to start working on date column, we will start with creating one more column (Last published) to cut the extra part of first published and make it easier to convert it to date, and we will take the other half of the first published and store it in newly created to column for future uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastPublishing(date):\n",
    "    if (date is not None):\n",
    "        d = date.split('–')\n",
    "        if (len(d) > 1):\n",
    "            return d[1]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['Last published'] = books_df['First published'].apply(lambda x: getLastPublishing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f07490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstPublishing(date):\n",
    "    if (date is not None):\n",
    "        d = date.split('–')\n",
    "        return d[0]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['First published'] = books_df['First published'].apply(lambda x: getFirstPublishing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a525b",
   "metadata": {},
   "source": [
    "#### As we have polished the first published column, there is still some data which has certain value format and as there is no more then 4 records with this format so we will manualy search them and fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02223c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df['First published'].loc[319] = '1965'\n",
    "books_df['First published'].loc[324] = '1965'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df[books_df['First published'].str.contains('Up to')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c622bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['First published'].loc[303] = books_df['First published'].loc[303].split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacba3ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df['First published'] = pd.to_datetime(books_df['First published'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90243339",
   "metadata": {},
   "source": [
    "#### the First published column has now the datetime type, now we can use it easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256b932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32d910",
   "metadata": {},
   "source": [
    "#### Now we have a ready dataset, it may still have some errors but we will fix it when needed. some columns still have multivalues like Author (s) column, we don't need to split them as it may create redundant rows so we will keep it as it is for now, but we will split them later on if we wanted to analysis based on these multivalue columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bc073",
   "metadata": {},
   "source": [
    "#### I have uploaded this dataset to kaggle, feel free to download it if you need it. the link for this dataset is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = books_df.replace('', np.nan)\n",
    "books_df = books_df.replace(np.nan, 'N/A') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60269b",
   "metadata": {},
   "source": [
    "#### There are some columns with some null values, but we can't fill these values as we don't have any other source to get info about this books, as they are all string values we cannot guess any suitable values for them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540872a",
   "metadata": {},
   "source": [
    "### 3: Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b236d",
   "metadata": {},
   "source": [
    "#### so lets get started with analysis and visualizations, we will answer some questions to get a better understanding of useful insights in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c5569",
   "metadata": {},
   "source": [
    "#### for visulization we are gonna use matplotlib and plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77686c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28054fd",
   "metadata": {},
   "source": [
    "#### Question 2: What books are sold the most (top 10)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f2c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_rb = books_df.sort_values(['Approximate sales'], ascending=False).head(10).sort_values('Approximate sales')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "bars = ax.barh(most_rb['Book'], most_rb['Approximate sales'])\n",
    "plt.ylabel('Books')\n",
    "plt.xlabel('Sales in millions')\n",
    "plt.bar_label(bars)\n",
    "plt.title(\"Top 10 most sold books\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f39786",
   "metadata": {},
   "source": [
    "#### Question 1: What books are sold the most in each type (top 10)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b51b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10individual_books = books_df[books_df['Book type'] == 'Individual'].sort_values(['Approximate sales'], ascending=False).head(10)\n",
    "top10individual_books = top10individual_books.sort_values(['Approximate sales'])\n",
    "\n",
    "top10series_books = books_df[books_df['Book type'] == 'Series'].sort_values(['Approximate sales'], ascending=False).head(10)\n",
    "top10series_books = top10series_books.sort_values(['Approximate sales'])\n",
    "\n",
    "top10regupd_books = books_df[books_df['Book type'] == 'Regularly Updated'].sort_values(['Approximate sales'], ascending=False).head(10)\n",
    "top10regupd_books = top10regupd_books.sort_values(['Approximate sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d563e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "bars = ax.barh(top10individual_books['Book'], top10individual_books['Approximate sales'])\n",
    "plt.ylabel('Books')\n",
    "plt.xlabel('Sales in millions')\n",
    "plt.bar_label(bars)\n",
    "plt.title(\"Top 10 most sold books (Individual)\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f73f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "bars = ax.barh(top10series_books['Book'], top10series_books['Approximate sales'])\n",
    "plt.ylabel('Books')\n",
    "plt.xlabel('Sales in millions')\n",
    "plt.bar_label(bars)\n",
    "plt.title(\"Top 10 sold read books (Series)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86f383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "bars = ax.barh(top10regupd_books['Book'], top10regupd_books['Approximate sales'])\n",
    "ax.set_ylabel('Books')\n",
    "ax.set_xlabel('Sales in millions')\n",
    "plt.bar_label(bars)\n",
    "plt.title(\"Top 10 most sold books (Regularly Updated)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695002b",
   "metadata": {},
   "source": [
    "#### Question 3: Which languages has the most books sold? (percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_df = books_df[['Original language','Approximate sales']].groupby('Original language').sum()\n",
    "lang_df = lang_df.reset_index('Original language').sort_values(['Approximate sales'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4fbe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.pie(lang_df, values='Approximate sales', names='Original language', title='Languages with the most books sold',                  \n",
    "       color_discrete_sequence=px.colors.qualitative.Set3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02426ba",
   "metadata": {},
   "source": [
    "#### Question 4: Find the trends of different types of highest sold books from 1800 on ward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27527c78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "typedata = books_df[['Book type', 'First published', 'Approximate sales']]\n",
    "typedata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329713fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tydata = typedata.groupby(['First published', 'Book type']).size().reset_index(name='Total Content')\n",
    "tydata = tydata.sort_values(['First published']).reset_index(drop=True)\n",
    "tydata = tydata[tydata['First published'] >='1800']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(tydata, x='First published', y='Total Content', color='Book type', \n",
    "        title='Trends in years (Highest sold books)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f99e5b",
   "metadata": {},
   "source": [
    "#### Question 5: Genres with the most sold books? (top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa03f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = books_df[books_df['Genre'] != 'N/A']\n",
    "genre_df = genre_df[['Genre', 'Approximate sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc67fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df['Genre'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = genre_df.groupby('Genre').size().reset_index(name=\"Total publishes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = genre_df.sort_values(['Total publishes'], ascending=False).head(10).sort_values(['Total publishes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f935e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df2 = books_df[books_df['Genre'] != 'N/A']\n",
    "genre_df2 = genre_df2[['Genre', 'Approximate sales']]\n",
    "genre_df2 = genre_df2.groupby('Genre').sum().sort_values('Approximate sales', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2579ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = pd.merge(genre_df2, genre_df, on='Genre', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937e5b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.bar(genre_df, x='Approximate sales', y='Genre', title='Genres total contents', color='Total publishes').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee39841",
   "metadata": {},
   "source": [
    "#### Question 6: Most successful Authors? (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea78757",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = books_df[books_df['Author(s)'].str.contains(',')][['Author(s)', 'Approximate sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = authors_df['Author(s)'].str.split(',', expand=True).stack().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526dde73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors.columns = ['Author(s)']\n",
    "authors = pd.merge(authors, books_df['Author(s)'], how='outer').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee4c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors = authors.drop(authors[authors['Author(s)'].str.contains(',')].index).reset_index(drop=True)\n",
    "authors = authors.drop(authors[authors['Author(s)'] == 'N/A'].index).reset_index(drop=True)\n",
    "authors = authors.drop(authors[authors['Author(s)'] == 'Various authors'].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83988795",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors.columns = ['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = authors.groupby('Author').size().reset_index(name='Total publishes').sort_values('Total publishes', ascending=False)\n",
    "authors = authors.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598761ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.bar(authors.sort_values('Total publishes'), x='Total publishes', y='Author', \n",
    "       title='Most contents published of an author', color='Total publishes').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a58bcc",
   "metadata": {},
   "source": [
    "#### Now we will answer the same question with different method and showing the amount of sales along with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "    # make sure `lst_cols` is list-alike\n",
    "    if (lst_cols is not None\n",
    "        and len(lst_cols) > 0\n",
    "        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "    # preserve original index values    \n",
    "    idx = np.repeat(df.index.values, lens)\n",
    "    # create \"exploded\" DF\n",
    "    res = (pd.DataFrame({\n",
    "                col:np.repeat(df[col].values, lens)\n",
    "                for col in idx_cols},\n",
    "                index=idx)\n",
    "             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                            for col in lst_cols}))\n",
    "    # append those rows that have empty lists\n",
    "    if (lens == 0).any():\n",
    "        # at least one list in cells is empty\n",
    "        res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                  .fillna(fill_value))\n",
    "    # revert the original index order\n",
    "    res = res.sort_index()\n",
    "    # reset index if requested\n",
    "    if not preserve_index:        \n",
    "        res = res.reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b415c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors = explode(books_df.assign(Author=books_df['Author(s)'].str.split(',')), 'Author')\n",
    "authors = authors[['Author', 'Approximate sales']]\n",
    "authors = authors.groupby('Author').sum().reset_index().sort_values('Approximate sales',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569ec53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors2 = explode(books_df.assign(Author=books_df['Author(s)'].str.split(',')), 'Author')\n",
    "authors2 = authors2[['Author', 'Approximate sales']]\n",
    "authors2 = authors2.groupby('Author').size()\n",
    "authors2 = authors2.reset_index(name='Total publishes').sort_values('Total publishes',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64026ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10authors = pd.merge(authors, authors2, how='outer').sort_values(['Approximate sales', 'Total publishes'], ascending=False)\n",
    "top10authors = top10authors[top10authors['Author'] != 'Various authors']\n",
    "top10authors = top10authors[top10authors['Author'] != 'N/A']\n",
    "top10authors = top10authors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19127522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getName(name):\n",
    "    s = name.split(\":\")\n",
    "    if (len(s)>1):\n",
    "        return s[1]\n",
    "    return name\n",
    "\n",
    "top10authors['Author'] = top10authors['Author'].apply(lambda x: getName(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e63348",
   "metadata": {},
   "source": [
    "#### Highest successful authors with approximate sales and total publishes (series and individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(top10authors.sort_values('Total publishes'), x='Total publishes', y='Author', \n",
    "       title='Most contents published of an author', color='Approximate sales').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b0ff0",
   "metadata": {},
   "source": [
    "#### Question 7: Which century were sold the most book? (After 18th century)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb0407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "typedata = books_df[['Book type', 'First published', 'Approximate sales']]\n",
    "typedata.isnull().sum()\n",
    "tydata = typedata.groupby(['First published', 'Book type']).sum()\n",
    "tydata = tydata.sort_values(['First published']).reset_index()\n",
    "tydata = tydata[tydata['First published'] >='1700']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "tydata['Century'] = tydata['First published'].str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f89afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tydata['Century'] = pd.to_numeric(tydata['Century'])\n",
    "tydata['Century'] = tydata['Century'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "tydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(tydata, x=\"Century\", y=\"Approximate sales\", color=\"Book type\", title=\"Best century for books\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb1a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26d3f57c2bfb08e947d480ae6a88ba7b7b6d2a1c35e8351528e35b4e112c4d61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
